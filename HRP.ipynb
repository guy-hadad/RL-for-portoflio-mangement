{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from matplotlib import pyplot as plt\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import ffn\n",
    "import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On 20151227 by MLdP <lopezdeprado@lbl.gov>\n",
    "# Hierarchical Risk Parity\n",
    "\n",
    "\n",
    "def getIVP(cov, **kargs):\n",
    "    # Compute the inverse-variance portfolio\n",
    "    ivp = 1. / np.diag(cov)\n",
    "    ivp /= ivp.sum()\n",
    "    return ivp\n",
    "\n",
    "\n",
    "def getClusterVar(cov,cItems):\n",
    "    # Compute variance per cluster\n",
    "    cov_=cov.loc[cItems,cItems] # matrix slice\n",
    "    w_=getIVP(cov_).reshape(-1,1)\n",
    "    cVar=np.dot(np.dot(w_.T,cov_),w_)[0,0]\n",
    "    return cVar\n",
    "\n",
    "\n",
    "def getQuasiDiag(link):\n",
    "    # Sort clustered items by distance\n",
    "    link = link.astype(int)\n",
    "    sortIx = pd.Series([link[-1, 0], link[-1, 1]])\n",
    "    numItems = link[-1, 3]  # number of original items\n",
    "    while sortIx.max() >= numItems:\n",
    "        sortIx.index = range(0, sortIx.shape[0] * 2, 2)  # make space\n",
    "        df0 = sortIx[sortIx >= numItems]  # find clusters\n",
    "        i = df0.index\n",
    "        j = df0.values - numItems\n",
    "        sortIx[i] = link[j, 0]  # item 1\n",
    "        df0 = pd.Series(link[j, 1], index=i + 1)\n",
    "        sortIx = sortIx.append(df0)  # item 2\n",
    "        sortIx = sortIx.sort_index()  # re-sort\n",
    "        sortIx.index = range(sortIx.shape[0])  # re-index\n",
    "    return sortIx.tolist()\n",
    "\n",
    "\n",
    "def getRecBipart(cov, sortIx):\n",
    "    # Compute HRP alloc\n",
    "    w = pd.Series(1, index=sortIx)\n",
    "    cItems = [sortIx]  # initialize all items in one cluster\n",
    "    while len(cItems) > 0:\n",
    "        cItems = [i[j:k] for i in cItems for j, k in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]  # bi-section\n",
    "        for i in range(0, len(cItems), 2):  # parse in pairs\n",
    "            cItems0 = cItems[i]  # cluster 1\n",
    "            cItems1 = cItems[i + 1]  # cluster 2\n",
    "            cVar0 = getClusterVar(cov, cItems0)\n",
    "            cVar1 = getClusterVar(cov, cItems1)\n",
    "            alpha = 1 - cVar0 / (cVar0 + cVar1)\n",
    "            w[cItems0] *= alpha  # weight 1\n",
    "            w[cItems1] *= 1 - alpha  # weight 2\n",
    "    return w\n",
    "\n",
    "\n",
    "def correlDist(corr):\n",
    "    # A distance matrix based on correlation, where 0<=d[i,j]<=1\n",
    "    # This is a proper distance metric\n",
    "    dist = ((1 - corr) / 2.)**.5  # distance matrix\n",
    "    return dist\n",
    "\n",
    "\n",
    "def getHRP(cov, corr):\n",
    "    # Construct a hierarchical portfolio\n",
    "    dist = correlDist(corr)\n",
    "    link = sch.linkage(dist, 'single')\n",
    "    #dn = sch.dendrogram(link, labels=cov.index.values, label_rotation=90)\n",
    "    #plt.show()\n",
    "    sortIx = getQuasiDiag(link)\n",
    "    sortIx = corr.index[sortIx].tolist()\n",
    "    hrp = getRecBipart(cov, sortIx)\n",
    "    return hrp.sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getMVP(cov):\n",
    "\n",
    "    cov = cov.T.values\n",
    "    n = len(cov)\n",
    "    N = 100\n",
    "    mus = [10 ** (5.0 * t / N - 1.0) for t in range(N)]\n",
    "\n",
    "    # Convert to cvxopt matrices\n",
    "    S = opt.matrix(cov)\n",
    "    #pbar = opt.matrix(np.mean(returns, axis=1))\n",
    "    pbar = opt.matrix(np.ones(cov.shape[0]))\n",
    "\n",
    "    # Create constraint matrices\n",
    "    G = -opt.matrix(np.eye(n))  # negative n x n identity matrix\n",
    "    h = opt.matrix(0.0, (n, 1))\n",
    "    A = opt.matrix(1.0, (1, n))\n",
    "    b = opt.matrix(1.0)\n",
    "\n",
    "    # Calculate efficient frontier weights using quadratic programming\n",
    "    portfolios = [solvers.qp(mu * S, -pbar, G, h, A, b)['x']\n",
    "                  for mu in mus]\n",
    "    ## CALCULATE RISKS AND RETURNS FOR FRONTIER\n",
    "    returns = [blas.dot(pbar, x) for x in portfolios]\n",
    "    risks = [np.sqrt(blas.dot(x, S * x)) for x in portfolios]\n",
    "    ## CALCULATE THE 2ND DEGREE POLYNOMIAL OF THE FRONTIER CURVE\n",
    "    m1 = np.polyfit(returns, risks, 2)\n",
    "    x1 = np.sqrt(m1[2] / m1[0])\n",
    "    # CALCULATE THE OPTIMAL PORTFOLIO\n",
    "    wt = solvers.qp(opt.matrix(x1 * S), -pbar, G, h, A, b)['x']\n",
    "\n",
    "    return list(wt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_all_portfolios(returns):\n",
    "    \n",
    "    cov, corr = returns.cov(), returns.corr()\n",
    "    hrp = getHRP(cov, corr)\n",
    "    ivp = getIVP(cov)\n",
    "    ivp = pd.Series(ivp, index=cov.index)\n",
    "    mvp = getMVP(cov)\n",
    "    mvp = pd.Series(mvp, index=cov.index)\n",
    "    \n",
    "    portfolios = pd.DataFrame([mvp, ivp, hrp], index=['MVP', 'IVP', 'HRP']).T\n",
    "    \n",
    "    return portfolios\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stocks = {\n",
    "    \"Apple\": \"AAPL\",\n",
    "    \"Amazon\": \"AMZN\",\n",
    "    \"Alphabet\": \"GOOG\",\n",
    "    \"Microsoft\": \"MSFT\",\n",
    "    \"Facebook\": \"FB\",\n",
    "    \"Alibaba\": \"BABA\",\n",
    "    \"Berkshire Hathaway\": \"BRK-A\",\n",
    "    \"Tencent\": \"TCEHY\",\n",
    "    \"JPMorgan\": \"JPM\",\n",
    "    \"ExxonMobil\": \"XOM\",\n",
    "    \"Johnson & Johnson\": \"JNJ\",\n",
    "    \"Samsung Electronics\": \"005930.KS\",\n",
    "    \"Bank of America\": \"BAC\"\n",
    "}\n",
    "stocks = pd.DataFrame(list(stocks.items()), columns=['name', 'symbol'])\n",
    "ts = TimeSeries(key=config.key, output_format='pandas')\n",
    "stocks_close = pd.DataFrame()\n",
    "for symbol in stocks.symbol.values:\n",
    "    data, _ = ts.get_daily(symbol=symbol, outputsize='full')\n",
    "    close = data['4. close']\n",
    "    close.index = pd.to_datetime(close.index)\n",
    "    stocks_close = stocks_close.append(close)\n",
    "stocks_close = stocks_close.T\n",
    "stocks_close = stocks_close.sort_index()\n",
    "stocks_close = stocks_close.fillna(method='ffill')\n",
    "stocks_close.columns = stocks.name.values\n",
    "stocks_close = stocks_close[\"2015-01-01\":\"2018-01-01\"]\n",
    "returns = stocks_close.to_returns().dropna()\n",
    "\n",
    "portfolios = get_all_portfolios(returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
